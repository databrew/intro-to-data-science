# Sentiment analysis with Harry Potter


&nbsp;  

**1.** Start a new script. Name it "harry.R".

**2.** Set up your work space by loading the `ggplot2`, `dplyr`, `tidytext`, `gsheet`, `wordcloud2`, `sentimentr`, and `lubridate` packages.

**3.** Read in your Harry Potter data by running the following:

```{r, eval = FALSE}
hp <- read_csv('https://raw.githubusercontent.com/databrew/intro-to-data-science/main/data/harrypotter.csv')
```

**4.** Take a peek at the first few rows of the data. What is the unit of observation?

**5.** Make all of the `text` column be lower case.

**6.** Make all of the `text` column be upper case.

**7.** Use `unnest_tokens` to create a dataframe with one row per word.

**8.** Create a variable named `word_length` with the number of characters in each word.

**9.** Make a histogram of word length.

**10.** Make a density chart of word length.

**11.** Make the density chart of word length have a different `fill` for each chapter.

**12.** Get the average word length per chapter.

**13.** Plot the average word length per chapter.

**14.** What is the longest word used in Harry Potter?

**15.** What is the most frequent word used in Harry Potter?

**16.** Get the number of words per chapter.

**17.** Plot the number of words per chapter.

**18.** What's the longest chapter in Harry Potter?

**19.** Run the below to create an object named `sw`.

```{r, eval = FALSE}
sw <- read_csv('https://raw.githubusercontent.com/databrew/intro-to-data-science/main/data/stopwords.csv')
```

**20.** Remove the stop words form your one-row-per-word dataframe.

**21.** What is the most frequently used (non-stop) word in Harry Potter?

**22.** Create an object called `sentiments` by running the following:

```{r, eval = FALSE}
sentiments <- get_sentiments('afinn')
```

**23.** Use `left_join` to bring a sentiment classification to each word.

**24.** Is Harry Potter more negative or positive?

**25.** Calculate the average sentimentality per chapter.

**26.** Plot the average sentimentality per chapter.

**27.** Create a variable called `cumulative_sentiment`. Use `cumsum` to get the cumulative sum sentimentality.

**28.** Plot cumulative sentiment.

**29.** Color your plot by chapter.





**14.** 


**15.** What is the `sw` object all about? Explore it a bit.


**4.** Take a look at the first few rows of the data. What is the unit of observation?

**5.** Create a variable named `date_time` in your `survey` data. This should be based on the `Timestamp` variable. Use the `mdy_hms` variable to created a "date-time" object.

**6.** Create a visualization of the `date_time` variable.

**7.** Create an object called `sentiments` by running the following:

```{r, eval = FALSE}
sentiments <- get_sentiments('bing')
```

**8.** Explore the `sentiments` object. How many rows? How many columns? What is the unit of observation.

**9.** Create an object named `words` by running the following:

```{r, eval = FALSE}
words <- survey %>%
  dplyr::select(first_name,
                feeling_num,
                feeling) %>%
  unnest_tokens(word, feeling)
```

**10.** Explore `words`. What is the unit of observation.

**11.** Look up the help documentation for the function `wordcloud2`. What does it expect as the first argument of the function?

**12.** Create a dataframe named `word_freq`. This should be a dataframe which is conformant with the expectation of `wordcloud2`, showing how frequently each word appeared in our `feeling`s.

**13.** Make a word cloud.




**16.** Remove from `word_freq` any rows in which the word appears in `sw`.

**17.** Make a new word cloud.

**18.** Make an object with the top 10 words used only. Name this object `top10`.

**19.** Create a bar chart showing the number of times the `top10` words were used.

**20.** Run the below to join `word_freq` with `sentiments`.

```{r, eval = FALSE}
joined <- left_join(word_freq, sentiments)
```

**21.** Now explore the data. What is going on?

**22.** For the whole survey, were there more negative or positive sentiment words used?

**23.** Create an object with the number of `negative` and `positive` words used for each person.

**24.** In that object, create a new variabled named `sentimentality`, which is the number of `positive` words minus the number of `negative` words.

**25.** Make a histogram of senitmentality

**26.** Make a barplot of sentimentality.

**27.** Create a wordcloud for the `dream` variable.

**28.** Create a barplot showing the top 16 words in our dreams.

**29.** Which word showed up most in people's description of Joe?

**30.** Make a histogram of `feeling_num`. 

**31.** Make a density chart of `feeling_num`.

**32.** Change the above plot to facet it by gender.

**33.** How many people mentioned Ryan Gosling in their description of Joe?

**34.** Is there a correlation between the sentimentality of people's `feeling` and their `feeling_num`?
